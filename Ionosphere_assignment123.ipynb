{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Ionosphere Data Problem\n",
    "\n",
    "### Dataset Description: \n",
    "\n",
    "This radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. See the paper for more details. The targets were free electrons in the ionosphere. \"Good\" radar returns are those showing evidence of some type of structure in the ionosphere. \"Bad\" returns are those that do not; their signals pass through the ionosphere.\n",
    "\n",
    "Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number. There were 17 pulse numbers for the Goose Bay system. Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "- All 34 are continuous\n",
    "- The 35th attribute is either \"good\" or \"bad\" according to the definition summarized above. This is a binary classification task.\n",
    "\n",
    " <br><br>\n",
    "\n",
    "<table border=\"1\"  cellpadding=\"6\">\n",
    "\t<tbody>\n",
    "        <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Multivariate</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">351</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Physical</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n",
    "            <td><p class=\"normal\">Integer,Real</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n",
    "            <td><p class=\"normal\">34</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n",
    "            <td><p class=\"normal\">N/A</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\t\n",
    "    <tbody>\n",
    "    <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Classification</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t</tr>\n",
    "    </tbody>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORKFLOW :\n",
    "- Load Data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset.\n",
    "df = pd.read_csv('ionosphere_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 35)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the shape of the dataset \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear from the shape of the data that dataset is not a huge one. Only 351 records are available with 34 features/columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0         1         0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1         1         0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2         1         0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3         1         0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4         1         0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "\n",
       "   feature8  feature9  feature10  ...  feature26  feature27  feature28  \\\n",
       "0  -0.37708   1.00000    0.03760  ...   -0.51171    0.41078   -0.46168   \n",
       "1  -0.93597   1.00000   -0.04549  ...   -0.26569   -0.20468   -0.18401   \n",
       "2  -0.12062   0.88965    0.01198  ...   -0.40220    0.58984   -0.22145   \n",
       "3  -1.00000   0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4  -0.23255   0.77152   -0.16399  ...   -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature1</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.891738</td>\n",
       "      <td>0.311155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature2</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature3</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>0.87111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature4</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.441435</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.01631</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature5</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.601068</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>0.80920</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature6</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.115889</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>0.02280</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature7</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>0.72873</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature8</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.01471</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature9</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>0.68421</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature10</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>0.483851</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.048075</td>\n",
       "      <td>0.01829</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature11</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.476183</td>\n",
       "      <td>0.563496</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.021120</td>\n",
       "      <td>0.66798</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature12</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.155040</td>\n",
       "      <td>0.494817</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.065265</td>\n",
       "      <td>0.02825</td>\n",
       "      <td>0.482375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature13</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.400801</td>\n",
       "      <td>0.622186</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.64407</td>\n",
       "      <td>0.955505</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature14</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.093414</td>\n",
       "      <td>0.494873</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.073725</td>\n",
       "      <td>0.03027</td>\n",
       "      <td>0.374860</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature15</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.344159</td>\n",
       "      <td>0.652828</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60194</td>\n",
       "      <td>0.919330</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature16</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.071132</td>\n",
       "      <td>0.458371</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.081705</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.308975</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature17</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.381949</td>\n",
       "      <td>0.618020</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.59091</td>\n",
       "      <td>0.935705</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature18</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.003617</td>\n",
       "      <td>0.496762</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.225690</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.195285</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature19</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.359390</td>\n",
       "      <td>0.626267</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57619</td>\n",
       "      <td>0.899265</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature20</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.024025</td>\n",
       "      <td>0.519076</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.234670</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.134370</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature21</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.336695</td>\n",
       "      <td>0.609828</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.49909</td>\n",
       "      <td>0.894865</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature22</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.008296</td>\n",
       "      <td>0.518166</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.243870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.188760</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature23</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.362475</td>\n",
       "      <td>0.603767</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.53176</td>\n",
       "      <td>0.911235</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature24</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.057406</td>\n",
       "      <td>0.527456</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.366885</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.164630</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature25</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.396135</td>\n",
       "      <td>0.578451</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.55389</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature26</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.332390</td>\n",
       "      <td>-0.01505</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature27</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.286435</td>\n",
       "      <td>0.70824</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature28</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.069538</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.443165</td>\n",
       "      <td>-0.01769</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature29</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>0.575886</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.49664</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature30</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature31</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>0.571483</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.44277</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature32</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.242595</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.200120</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature33</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.522663</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.40956</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature34</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.014480</td>\n",
       "      <td>0.468337</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.165350</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.171660</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count      mean       std  min       25%      50%       75%  max\n",
       "feature1   351.0  0.891738  0.311155  0.0  1.000000  1.00000  1.000000  1.0\n",
       "feature2   351.0  0.000000  0.000000  0.0  0.000000  0.00000  0.000000  0.0\n",
       "feature3   351.0  0.641342  0.497708 -1.0  0.472135  0.87111  1.000000  1.0\n",
       "feature4   351.0  0.044372  0.441435 -1.0 -0.064735  0.01631  0.194185  1.0\n",
       "feature5   351.0  0.601068  0.519862 -1.0  0.412660  0.80920  1.000000  1.0\n",
       "feature6   351.0  0.115889  0.460810 -1.0 -0.024795  0.02280  0.334655  1.0\n",
       "feature7   351.0  0.550095  0.492654 -1.0  0.211310  0.72873  0.969240  1.0\n",
       "feature8   351.0  0.119360  0.520750 -1.0 -0.054840  0.01471  0.445675  1.0\n",
       "feature9   351.0  0.511848  0.507066 -1.0  0.087110  0.68421  0.953240  1.0\n",
       "feature10  351.0  0.181345  0.483851 -1.0 -0.048075  0.01829  0.534195  1.0\n",
       "feature11  351.0  0.476183  0.563496 -1.0  0.021120  0.66798  0.957895  1.0\n",
       "feature12  351.0  0.155040  0.494817 -1.0 -0.065265  0.02825  0.482375  1.0\n",
       "feature13  351.0  0.400801  0.622186 -1.0  0.000000  0.64407  0.955505  1.0\n",
       "feature14  351.0  0.093414  0.494873 -1.0 -0.073725  0.03027  0.374860  1.0\n",
       "feature15  351.0  0.344159  0.652828 -1.0  0.000000  0.60194  0.919330  1.0\n",
       "feature16  351.0  0.071132  0.458371 -1.0 -0.081705  0.00000  0.308975  1.0\n",
       "feature17  351.0  0.381949  0.618020 -1.0  0.000000  0.59091  0.935705  1.0\n",
       "feature18  351.0 -0.003617  0.496762 -1.0 -0.225690  0.00000  0.195285  1.0\n",
       "feature19  351.0  0.359390  0.626267 -1.0  0.000000  0.57619  0.899265  1.0\n",
       "feature20  351.0 -0.024025  0.519076 -1.0 -0.234670  0.00000  0.134370  1.0\n",
       "feature21  351.0  0.336695  0.609828 -1.0  0.000000  0.49909  0.894865  1.0\n",
       "feature22  351.0  0.008296  0.518166 -1.0 -0.243870  0.00000  0.188760  1.0\n",
       "feature23  351.0  0.362475  0.603767 -1.0  0.000000  0.53176  0.911235  1.0\n",
       "feature24  351.0 -0.057406  0.527456 -1.0 -0.366885  0.00000  0.164630  1.0\n",
       "feature25  351.0  0.396135  0.578451 -1.0  0.000000  0.55389  0.905240  1.0\n",
       "feature26  351.0 -0.071187  0.508495 -1.0 -0.332390 -0.01505  0.156765  1.0\n",
       "feature27  351.0  0.541641  0.516205 -1.0  0.286435  0.70824  0.999945  1.0\n",
       "feature28  351.0 -0.069538  0.550025 -1.0 -0.443165 -0.01769  0.153535  1.0\n",
       "feature29  351.0  0.378445  0.575886 -1.0  0.000000  0.49664  0.883465  1.0\n",
       "feature30  351.0 -0.027907  0.507974 -1.0 -0.236885  0.00000  0.154075  1.0\n",
       "feature31  351.0  0.352514  0.571483 -1.0  0.000000  0.44277  0.857620  1.0\n",
       "feature32  351.0 -0.003794  0.513574 -1.0 -0.242595  0.00000  0.200120  1.0\n",
       "feature33  351.0  0.349364  0.522663 -1.0  0.000000  0.40956  0.813765  1.0\n",
       "feature34  351.0  0.014480  0.468337 -1.0 -0.165350  0.00000  0.171660  1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1\n",
      "2\n",
      "feature2\n",
      "1\n",
      "feature3\n",
      "219\n",
      "feature4\n",
      "269\n",
      "feature5\n",
      "204\n",
      "feature6\n",
      "259\n",
      "feature7\n",
      "231\n",
      "feature8\n",
      "260\n",
      "feature9\n",
      "244\n",
      "feature10\n",
      "267\n",
      "feature11\n",
      "246\n",
      "feature12\n",
      "269\n",
      "feature13\n",
      "238\n",
      "feature14\n",
      "266\n",
      "feature15\n",
      "234\n",
      "feature16\n",
      "270\n",
      "feature17\n",
      "254\n",
      "feature18\n",
      "280\n",
      "feature19\n",
      "254\n",
      "feature20\n",
      "266\n",
      "feature21\n",
      "248\n",
      "feature22\n",
      "265\n",
      "feature23\n",
      "248\n",
      "feature24\n",
      "264\n",
      "feature25\n",
      "256\n",
      "feature26\n",
      "273\n",
      "feature27\n",
      "256\n",
      "feature28\n",
      "281\n",
      "feature29\n",
      "244\n",
      "feature30\n",
      "266\n",
      "feature31\n",
      "243\n",
      "feature32\n",
      "263\n",
      "feature33\n",
      "245\n",
      "feature34\n",
      "263\n",
      "label\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for feature in df:\n",
    "    print(feature)\n",
    "    print(len(df[feature].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['feature2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[1], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>0.50874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>0.73082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>0.52798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature3  feature4  feature5  feature6  feature7  feature8  \\\n",
       "0         1   0.99539  -0.05889   0.85243   0.02306   0.83398  -0.37708   \n",
       "1         1   1.00000  -0.18829   0.93035  -0.36156  -0.10868  -0.93597   \n",
       "2         1   1.00000  -0.03365   1.00000   0.00485   1.00000  -0.12062   \n",
       "3         1   1.00000  -0.45161   1.00000   1.00000   0.71216  -1.00000   \n",
       "4         1   1.00000  -0.02401   0.94140   0.06531   0.92106  -0.23255   \n",
       "\n",
       "   feature9  feature10  feature11  ...  feature26  feature27  feature28  \\\n",
       "0   1.00000    0.03760    0.85243  ...   -0.51171    0.41078   -0.46168   \n",
       "1   1.00000   -0.04549    0.50874  ...   -0.26569   -0.20468   -0.18401   \n",
       "2   0.88965    0.01198    0.73082  ...   -0.40220    0.58984   -0.22145   \n",
       "3   0.00000    0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4   0.77152   -0.16399    0.52798  ...   -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.891738</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.601068</td>\n",
       "      <td>0.115889</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>0.476183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396135</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>-0.069538</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.014480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.311155</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>0.441435</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.483851</td>\n",
       "      <td>0.563496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578451</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>0.575886</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>0.571483</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>0.522663</td>\n",
       "      <td>0.468337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>-0.048075</td>\n",
       "      <td>0.021120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.332390</td>\n",
       "      <td>0.286435</td>\n",
       "      <td>-0.443165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.242595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871110</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.728730</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.684210</td>\n",
       "      <td>0.018290</td>\n",
       "      <td>0.667980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553890</td>\n",
       "      <td>-0.015050</td>\n",
       "      <td>0.708240</td>\n",
       "      <td>-0.017690</td>\n",
       "      <td>0.496640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409560</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>0.200120</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>0.171660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature1    feature3    feature4    feature5    feature6    feature7  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean     0.891738    0.641342    0.044372    0.601068    0.115889    0.550095   \n",
       "std      0.311155    0.497708    0.441435    0.519862    0.460810    0.492654   \n",
       "min      0.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      1.000000    0.472135   -0.064735    0.412660   -0.024795    0.211310   \n",
       "50%      1.000000    0.871110    0.016310    0.809200    0.022800    0.728730   \n",
       "75%      1.000000    1.000000    0.194185    1.000000    0.334655    0.969240   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         feature8    feature9   feature10   feature11  ...   feature25  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  ...  351.000000   \n",
       "mean     0.119360    0.511848    0.181345    0.476183  ...    0.396135   \n",
       "std      0.520750    0.507066    0.483851    0.563496  ...    0.578451   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000  ...   -1.000000   \n",
       "25%     -0.054840    0.087110   -0.048075    0.021120  ...    0.000000   \n",
       "50%      0.014710    0.684210    0.018290    0.667980  ...    0.553890   \n",
       "75%      0.445675    0.953240    0.534195    0.957895  ...    0.905240   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "        feature26   feature27   feature28   feature29   feature30   feature31  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean    -0.071187    0.541641   -0.069538    0.378445   -0.027907    0.352514   \n",
       "std      0.508495    0.516205    0.550025    0.575886    0.507974    0.571483   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%     -0.332390    0.286435   -0.443165    0.000000   -0.236885    0.000000   \n",
       "50%     -0.015050    0.708240   -0.017690    0.496640    0.000000    0.442770   \n",
       "75%      0.156765    0.999945    0.153535    0.883465    0.154075    0.857620   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        feature32   feature33   feature34  \n",
       "count  351.000000  351.000000  351.000000  \n",
       "mean    -0.003794    0.349364    0.014480  \n",
       "std      0.513574    0.522663    0.468337  \n",
       "min     -1.000000   -1.000000   -1.000000  \n",
       "25%     -0.242595    0.000000   -0.165350  \n",
       "50%      0.000000    0.409560    0.000000  \n",
       "75%      0.200120    0.813765    0.171660  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check Missing Values ( If Exist ; Fill each record with mean of its feature ) or any usless column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1     0\n",
       "feature3     0\n",
       "feature4     0\n",
       "feature5     0\n",
       "feature6     0\n",
       "feature7     0\n",
       "feature8     0\n",
       "feature9     0\n",
       "feature10    0\n",
       "feature11    0\n",
       "feature12    0\n",
       "feature13    0\n",
       "feature14    0\n",
       "feature15    0\n",
       "feature16    0\n",
       "feature17    0\n",
       "feature18    0\n",
       "feature19    0\n",
       "feature20    0\n",
       "feature21    0\n",
       "feature22    0\n",
       "feature23    0\n",
       "feature24    0\n",
       "feature25    0\n",
       "feature26    0\n",
       "feature27    0\n",
       "feature28    0\n",
       "feature29    0\n",
       "feature30    0\n",
       "feature31    0\n",
       "feature32    0\n",
       "feature33    0\n",
       "feature34    0\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = [1 if lbl == 'g' else 0 for lbl in df['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.sample(frac= 0.6, random_state=125)\n",
    "test_data = df.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_data.iloc[:,-1]\n",
    "train_data = train_data.iloc[:,0:-1]\n",
    "test_label = test_data.iloc[:,-1]\n",
    "test_data = test_data.iloc[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns= 'label', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.08013</td>\n",
       "      <td>0.96775</td>\n",
       "      <td>-0.00482</td>\n",
       "      <td>0.96683</td>\n",
       "      <td>-0.00722</td>\n",
       "      <td>0.87980</td>\n",
       "      <td>-0.03923</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98164</td>\n",
       "      <td>0.02003</td>\n",
       "      <td>0.93772</td>\n",
       "      <td>-0.03034</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.05843</td>\n",
       "      <td>0.92774</td>\n",
       "      <td>-0.03464</td>\n",
       "      <td>0.92226</td>\n",
       "      <td>-0.03673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.14754</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.04918</td>\n",
       "      <td>0.57377</td>\n",
       "      <td>-0.01639</td>\n",
       "      <td>0.65574</td>\n",
       "      <td>0.01639</td>\n",
       "      <td>0.85246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31148</td>\n",
       "      <td>-0.34426</td>\n",
       "      <td>0.52385</td>\n",
       "      <td>-0.20325</td>\n",
       "      <td>0.32787</td>\n",
       "      <td>-0.03279</td>\n",
       "      <td>0.27869</td>\n",
       "      <td>-0.44262</td>\n",
       "      <td>0.49180</td>\n",
       "      <td>-0.06557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1</td>\n",
       "      <td>0.89706</td>\n",
       "      <td>0.38235</td>\n",
       "      <td>0.91176</td>\n",
       "      <td>0.37500</td>\n",
       "      <td>0.74265</td>\n",
       "      <td>0.67647</td>\n",
       "      <td>0.45588</td>\n",
       "      <td>0.77941</td>\n",
       "      <td>0.19118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.74265</td>\n",
       "      <td>-0.12500</td>\n",
       "      <td>-0.67925</td>\n",
       "      <td>-0.24131</td>\n",
       "      <td>-0.55147</td>\n",
       "      <td>-0.42647</td>\n",
       "      <td>-0.44118</td>\n",
       "      <td>-0.50735</td>\n",
       "      <td>-0.28676</td>\n",
       "      <td>-0.56618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "      <td>0.84557</td>\n",
       "      <td>-0.08580</td>\n",
       "      <td>-0.31745</td>\n",
       "      <td>-0.80553</td>\n",
       "      <td>-0.08961</td>\n",
       "      <td>-0.56435</td>\n",
       "      <td>0.80648</td>\n",
       "      <td>0.04576</td>\n",
       "      <td>0.89514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78932</td>\n",
       "      <td>-0.03718</td>\n",
       "      <td>0.70882</td>\n",
       "      <td>-0.25288</td>\n",
       "      <td>0.77884</td>\n",
       "      <td>-0.14109</td>\n",
       "      <td>-0.21354</td>\n",
       "      <td>-0.78170</td>\n",
       "      <td>-0.18494</td>\n",
       "      <td>-0.59867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.77941</td>\n",
       "      <td>-0.99265</td>\n",
       "      <td>0.80882</td>\n",
       "      <td>0.55147</td>\n",
       "      <td>-0.41912</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature1  feature3  feature4  feature5  feature6  feature7  feature8  \\\n",
       "270         1   1.00000   0.08013   0.96775  -0.00482   0.96683  -0.00722   \n",
       "116         1   1.00000  -0.14754   1.00000   0.04918   0.57377  -0.01639   \n",
       "135         1   0.89706   0.38235   0.91176   0.37500   0.74265   0.67647   \n",
       "91          1   0.84557  -0.08580  -0.31745  -0.80553  -0.08961  -0.56435   \n",
       "100         1   1.00000  -1.00000   0.00000   0.00000   0.77941  -0.99265   \n",
       "\n",
       "     feature9  feature10  feature11  ...  feature25  feature26  feature27  \\\n",
       "270   0.87980   -0.03923    1.00000  ...    0.98164    0.02003    0.93772   \n",
       "116   0.65574    0.01639    0.85246  ...    0.31148   -0.34426    0.52385   \n",
       "135   0.45588    0.77941    0.19118  ...   -0.74265   -0.12500   -0.67925   \n",
       "91    0.80648    0.04576    0.89514  ...    0.78932   -0.03718    0.70882   \n",
       "100   0.80882    0.55147   -0.41912  ...   -1.00000   -1.00000   -1.00000   \n",
       "\n",
       "     feature28  feature29  feature30  feature31  feature32  feature33  \\\n",
       "270   -0.03034    1.00000   -0.05843    0.92774   -0.03464    0.92226   \n",
       "116   -0.20325    0.32787   -0.03279    0.27869   -0.44262    0.49180   \n",
       "135   -0.24131   -0.55147   -0.42647   -0.44118   -0.50735   -0.28676   \n",
       "91    -0.25288    0.77884   -0.14109   -0.21354   -0.78170   -0.18494   \n",
       "100   -1.00000    1.00000   -1.00000    1.00000   -1.00000    0.00000   \n",
       "\n",
       "     feature34  \n",
       "270   -0.03673  \n",
       "116   -0.06557  \n",
       "135   -0.56618  \n",
       "91    -0.59867  \n",
       "100    0.00000  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270    1\n",
       "116    0\n",
       "135    1\n",
       "91     0\n",
       "100    0\n",
       "      ..\n",
       "213    1\n",
       "161    1\n",
       "141    1\n",
       "59     0\n",
       "113    1\n",
       "Name: label, Length: 211, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_label.to_numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_label.to_numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set = np.array(train_set.as_matrix())\n",
    "#train_label = np.array(pd.DataFrame(train_label).as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))\n",
    "print(type(train_label))\n",
    "print(type(test_data))\n",
    "print(type(test_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float32\n",
      "float32\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.dtype)\n",
    "print(train_label.dtype)\n",
    "print(test_label.dtype)\n",
    "print(test_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,  activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                2176      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 6,401\n",
      "Trainable params: 6,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model.compile(optimizer = 'RMSprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train the Model with Epochs (100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "11/11 [==============================] - 1s 85ms/step - loss: 0.6157 - accuracy: 0.6607 - val_loss: 0.4872 - val_accuracy: 0.7907\n",
      "Epoch 2/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5509 - accuracy: 0.7560 - val_loss: 0.4378 - val_accuracy: 0.8372\n",
      "Epoch 3/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.7917 - val_loss: 0.4000 - val_accuracy: 0.8837\n",
      "Epoch 4/75\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.8333 - val_loss: 0.3593 - val_accuracy: 0.9535\n",
      "Epoch 5/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8750 - val_loss: 0.3283 - val_accuracy: 0.9535\n",
      "Epoch 6/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.8929 - val_loss: 0.2932 - val_accuracy: 0.9535\n",
      "Epoch 7/75\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.9048 - val_loss: 0.2641 - val_accuracy: 0.9535\n",
      "Epoch 8/75\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3020 - accuracy: 0.9167 - val_loss: 0.2405 - val_accuracy: 0.9535\n",
      "Epoch 9/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2952 - accuracy: 0.9167 - val_loss: 0.2223 - val_accuracy: 0.9767\n",
      "Epoch 10/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2642 - accuracy: 0.9226 - val_loss: 0.2096 - val_accuracy: 0.9767\n",
      "Epoch 11/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2375 - accuracy: 0.9107 - val_loss: 0.1948 - val_accuracy: 0.9767\n",
      "Epoch 12/75\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2091 - accuracy: 0.9226 - val_loss: 0.1862 - val_accuracy: 0.9767\n",
      "Epoch 13/75\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1919 - accuracy: 0.9405 - val_loss: 0.1803 - val_accuracy: 0.9767\n",
      "Epoch 14/75\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2002 - accuracy: 0.9464 - val_loss: 0.1760 - val_accuracy: 0.9767\n",
      "Epoch 15/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1765 - accuracy: 0.9464 - val_loss: 0.1696 - val_accuracy: 0.9767\n",
      "Epoch 16/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1701 - accuracy: 0.9464 - val_loss: 0.1613 - val_accuracy: 0.9767\n",
      "Epoch 17/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1494 - accuracy: 0.9405 - val_loss: 0.1601 - val_accuracy: 0.9767\n",
      "Epoch 18/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1635 - accuracy: 0.9524 - val_loss: 0.1586 - val_accuracy: 0.9767\n",
      "Epoch 19/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1243 - accuracy: 0.9702 - val_loss: 0.1579 - val_accuracy: 0.9767\n",
      "Epoch 20/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1385 - accuracy: 0.9583 - val_loss: 0.1579 - val_accuracy: 0.9767\n",
      "Epoch 21/75\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1102 - accuracy: 0.9643 - val_loss: 0.1555 - val_accuracy: 0.9767\n",
      "Epoch 22/75\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1103 - accuracy: 0.9821 - val_loss: 0.1577 - val_accuracy: 0.9767\n",
      "Epoch 23/75\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1143 - accuracy: 0.9702 - val_loss: 0.1616 - val_accuracy: 0.9767\n",
      "Epoch 24/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1139 - accuracy: 0.9643 - val_loss: 0.1753 - val_accuracy: 0.9767\n",
      "Epoch 25/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0933 - accuracy: 0.9702 - val_loss: 0.1609 - val_accuracy: 0.9767\n",
      "Epoch 26/75\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9643 - val_loss: 0.1521 - val_accuracy: 0.9767\n",
      "Epoch 27/75\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0973 - accuracy: 0.9643 - val_loss: 0.1507 - val_accuracy: 0.9767\n",
      "Epoch 28/75\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0903 - accuracy: 0.9762 - val_loss: 0.1489 - val_accuracy: 0.9767\n",
      "Epoch 29/75\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0772 - accuracy: 0.9762 - val_loss: 0.1617 - val_accuracy: 0.9767\n",
      "Epoch 30/75\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0951 - accuracy: 0.9702 - val_loss: 0.1397 - val_accuracy: 0.9767\n",
      "Epoch 31/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0598 - accuracy: 0.9881 - val_loss: 0.1429 - val_accuracy: 0.9767\n",
      "Epoch 32/75\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0741 - accuracy: 0.9821 - val_loss: 0.1634 - val_accuracy: 0.9767\n",
      "Epoch 33/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0740 - accuracy: 0.9821 - val_loss: 0.1508 - val_accuracy: 0.9767\n",
      "Epoch 34/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0613 - accuracy: 0.9881 - val_loss: 0.1520 - val_accuracy: 0.9767\n",
      "Epoch 35/75\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0650 - accuracy: 0.9762 - val_loss: 0.1427 - val_accuracy: 0.9767\n",
      "Epoch 36/75\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0593 - accuracy: 0.9821 - val_loss: 0.1397 - val_accuracy: 0.9767\n",
      "Epoch 37/75\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0496 - accuracy: 0.9881 - val_loss: 0.1395 - val_accuracy: 0.9767\n",
      "Epoch 38/75\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0589 - accuracy: 0.9881 - val_loss: 0.1340 - val_accuracy: 0.9767\n",
      "Epoch 39/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0555 - accuracy: 0.9821 - val_loss: 0.1166 - val_accuracy: 0.9767\n",
      "Epoch 40/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0621 - accuracy: 0.9762 - val_loss: 0.1157 - val_accuracy: 0.9767\n",
      "Epoch 41/75\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0419 - accuracy: 0.9881 - val_loss: 0.1212 - val_accuracy: 0.9767\n",
      "Epoch 42/75\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0533 - accuracy: 0.9881 - val_loss: 0.1306 - val_accuracy: 0.9767\n",
      "Epoch 43/75\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0464 - accuracy: 0.9881 - val_loss: 0.1225 - val_accuracy: 0.9767\n",
      "Epoch 44/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0509 - accuracy: 0.9821 - val_loss: 0.1105 - val_accuracy: 0.9767\n",
      "Epoch 45/75\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.9762 - val_loss: 0.1376 - val_accuracy: 0.9767\n",
      "Epoch 46/75\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9881 - val_loss: 0.1252 - val_accuracy: 0.9767\n",
      "Epoch 47/75\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0363 - accuracy: 0.9940 - val_loss: 0.1369 - val_accuracy: 0.9767\n",
      "Epoch 48/75\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0391 - accuracy: 0.9881 - val_loss: 0.1477 - val_accuracy: 0.9767\n",
      "Epoch 49/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0334 - accuracy: 0.9881 - val_loss: 0.1297 - val_accuracy: 0.9767\n",
      "Epoch 50/75\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0631 - accuracy: 0.9762 - val_loss: 0.1064 - val_accuracy: 0.9767\n",
      "Epoch 51/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0475 - accuracy: 0.9762 - val_loss: 0.0926 - val_accuracy: 0.9767\n",
      "Epoch 52/75\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.9881 - val_loss: 0.1042 - val_accuracy: 0.9767\n",
      "Epoch 53/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0364 - accuracy: 0.9881 - val_loss: 0.1121 - val_accuracy: 0.9767\n",
      "Epoch 54/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0293 - accuracy: 0.9881 - val_loss: 0.1201 - val_accuracy: 0.9767\n",
      "Epoch 55/75\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0279 - accuracy: 0.9881 - val_loss: 0.1132 - val_accuracy: 0.9767\n",
      "Epoch 56/75\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0401 - accuracy: 0.9881 - val_loss: 0.1329 - val_accuracy: 0.9767\n",
      "Epoch 57/75\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0216 - accuracy: 0.9940 - val_loss: 0.1353 - val_accuracy: 0.9767\n",
      "Epoch 58/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0330 - accuracy: 0.9881 - val_loss: 0.1139 - val_accuracy: 0.9767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/75\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0384 - accuracy: 0.9940 - val_loss: 0.1094 - val_accuracy: 0.9767\n",
      "Epoch 60/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0262 - accuracy: 0.9940 - val_loss: 0.1016 - val_accuracy: 0.9767\n",
      "Epoch 61/75\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9881 - val_loss: 0.1092 - val_accuracy: 0.9767\n",
      "Epoch 62/75\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.00 - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9940 - val_loss: 0.0899 - val_accuracy: 0.9767\n",
      "Epoch 63/75\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0377 - accuracy: 0.9821 - val_loss: 0.0787 - val_accuracy: 0.9535\n",
      "Epoch 64/75\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0346 - accuracy: 0.9940 - val_loss: 0.0882 - val_accuracy: 0.9767\n",
      "Epoch 65/75\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0337 - accuracy: 0.9821 - val_loss: 0.0696 - val_accuracy: 0.9767\n",
      "Epoch 66/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9767\n",
      "Epoch 67/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0406 - accuracy: 0.9821 - val_loss: 0.0644 - val_accuracy: 0.9767\n",
      "Epoch 68/75\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0239 - accuracy: 0.9940 - val_loss: 0.0882 - val_accuracy: 0.9767\n",
      "Epoch 69/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.0767 - val_accuracy: 0.9767\n",
      "Epoch 70/75\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9767\n",
      "Epoch 71/75\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0127 - accuracy: 0.9940 - val_loss: 0.1118 - val_accuracy: 0.9767\n",
      "Epoch 72/75\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9767\n",
      "Epoch 73/75\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9767\n",
      "Epoch 74/75\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0110 - accuracy: 0.9940 - val_loss: 0.0582 - val_accuracy: 0.9767\n",
      "Epoch 75/75\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0699 - val_accuracy: 0.9767\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_label, validation_split=0.2, epochs=75, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(75)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluation Step\n",
    "- Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.9429\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.25289714336395264, 0.9428571462631226]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
    "- Prediction should be > **92%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (predictions > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[48,  7],\n",
       "       [ 1, 84]])>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.confusion_matrix(\n",
    "    test_label, y_pred, num_classes=2, weights=None, dtype=tf.dtypes.int32,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    " # It will evaluate the logical expression y_predict>0.25 and return True or False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
