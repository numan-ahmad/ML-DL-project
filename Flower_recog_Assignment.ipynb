{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXgJ6uT1NydQ"
   },
   "source": [
    "Assignment: Flowers Recognition <br>\n",
    "Dataset Description:<br>\n",
    "\n",
    "This dataset contains 4242 images of flowers.<br>\n",
    "The data collection is based on the data flicr, google images, yandex images.<br>\n",
    "You can use this datastet to recognize plants from the photo.<br>\n",
    "\n",
    "Attribute Information:<br>\n",
    "The pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion.<br>\n",
    "For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. <br>\n",
    "<b>Also explore how to resize images in tensorflow and then resize all the images to a same size. </b> <br>\n",
    "This is a Multiclass Classification Problem.<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7vy-ktuOKJH"
   },
   "source": [
    "WORKFLOW : <br>\n",
    "Load Data <br>\n",
    "Split into 60 and 40 ratio.<br>\n",
    "Encode labels.<br>\n",
    "Create Model<br>\n",
    "Compilation Step (Note : Its a Multiclass Classification problem , select loss , metrics according to it)<br>\n",
    "Train the Model.<br>\n",
    "If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .<br>\n",
    "Prediction should be > 85%<br>\n",
    "Evaluation Step<br>\n",
    "Prediction<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ri3Bg5qfPRic"
   },
   "source": [
    "Data : <br>\n",
    "https://drive.google.com/file/d/1-OX6wn5gA-bJpjPNfSyaYQLz-A-AB_uj/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hTtg3WuGTA1o"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "IMG_DIR='./daisy'\n",
    "IMG_DIR1='./dandelion'\n",
    "IMG_DIR2='./rose'\n",
    "IMG_DIR3='./sunflower'\n",
    "IMG_DIR4='./tulip'\n",
    "\n",
    "def read_images(directory):\n",
    "    for img in glob.glob(directory+\"/*.jpg\"):\n",
    "        image = cv2.imread(img)\n",
    "        resized_img = cv2.resize(image/255.0  , (150 , 150))\n",
    "\n",
    "        yield resized_img\n",
    "\n",
    "resized_imgs0 =  np.array(list(read_images(IMG_DIR)))\n",
    "resized_imgs1 =  np.array(list(read_images(IMG_DIR1)))\n",
    "resized_imgs2 =  np.array(list(read_images(IMG_DIR2)))\n",
    "resized_imgs3 =  np.array(list(read_images(IMG_DIR3)))\n",
    "resized_imgs4 =  np.array(list(read_images(IMG_DIR4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label0 = np.zeros((resized_imgs0.shape[0],1))   #0\n",
    "label1 = np.ones((resized_imgs1.shape[0],1))  #1\n",
    "label2 = np.ones((resized_imgs2.shape[0],1))*2 #2\n",
    "label3 = np.ones((resized_imgs3.shape[0],1))*3 #3\n",
    "label4 = np.ones((resized_imgs4.shape[0],1))*4  #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((resized_imgs0,resized_imgs1,resized_imgs2,resized_imgs3,resized_imgs4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del resized_imgs0 \n",
    "del resized_imgs1 \n",
    "del resized_imgs2 \n",
    "del resized_imgs3 \n",
    "del resized_imgs4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate((label0,label1,label2,label3,label4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del label0\n",
    "del label1\n",
    "del label2\n",
    "del label3\n",
    "del label4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [4.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4323, 240, 320, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,train_labels  = unison_shuffled_copies(data,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "mask = np.random.rand(len(train_data)) < 0.7\n",
    "train = train_data[mask]\n",
    "test_data = train_data[~mask]\n",
    "label = train_labels[mask]\n",
    "test_label = train_labels[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(1234)\n",
    "# mask = np.random.rand(len(train_data)) < 0.7\n",
    "# train = train_data[mask]\n",
    "# test_data = train_data[~mask]\n",
    "# label = train_labels[mask]\n",
    "# test_label = train_labels[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reshape(3004,230400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.reshape(test_data.shape[0], test_data.shape[1]*test_data.shape[2]*test_data.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = label.reshape(3004,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3004,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3004, 230400)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(label)\n",
    "test_labels = to_categorical(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "def model_make():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(10, activation='relu', input_shape=(230400,)))\n",
    "    model.add(layers.Dense(8, activation='relu'))\n",
    "    model.add(layers.Dense(5, activation='softmax'))\n",
    "#     model.fit_generator()\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751\n",
      "processing fold # 0\n",
      "(751, 230400)\n",
      "(751,)\n",
      "(2253, 230400)\n",
      "(2253, 5)\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 5s 37ms/step - loss: 5.6183 - accuracy: 0.2226\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 4s 37ms/step - loss: 1.6157 - accuracy: 0.2521\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 4s 40ms/step - loss: 1.6378 - accuracy: 0.2395\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 5s 41ms/step - loss: 1.5957 - accuracy: 0.2547\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 5s 41ms/step - loss: 1.5949 - accuracy: 0.2492\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 5s 43ms/step - loss: 1.5976 - accuracy: 0.2486\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 5s 46ms/step - loss: 1.5909 - accuracy: 0.2597\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 5s 47ms/step - loss: 1.5933 - accuracy: 0.2576\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 5s 47ms/step - loss: 1.5935 - accuracy: 0.2386\n",
      "Epoch 10/10\n",
      " 86/113 [=====================>........] - ETA: 1s - loss: 1.5967 - accuracy: 0.2406"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "num_val_samples = len(train) //4\n",
    "\n",
    "print(num_val_samples)\n",
    "num_epochs = 10\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    print(val_data.shape)\n",
    "    val_targets = label[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    print(val_targets.shape)\n",
    "    partial_train_data = np.concatenate([train[:i * num_val_samples],train[(i + 1) * num_val_samples:]],axis=0)\n",
    "    partial_train_targets = np.concatenate([train_labels[:i * num_val_samples],train_labels[(i + 1) * num_val_samples:]],axis=0)\n",
    "    print(partial_train_data.shape)\n",
    "    print(partial_train_targets.shape)\n",
    "    model = model_make()\n",
    "    model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=20, verbose=1)\n",
    "    loss, val_accuracy = model.evaluate(val_data, val_targets, verbose=1)\n",
    "    all_scores.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_val = train[:1000]\n",
    "# partial_x_train = train[1000:]\n",
    "# y_val = train_labels[:1000]\n",
    "# partial_y_train = train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(partial_x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(partial_x_train,\n",
    "# partial_y_train,\n",
    "# epochs=20,\n",
    "# batch_size=512,\n",
    "# validation_data=(x_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Flowers Recognition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
